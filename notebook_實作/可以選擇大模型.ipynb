{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose a model from the following options:\n",
      "1. gpt-3.5-turbo series\n",
      "2. ollama\n",
      "3. LM Studio\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Plot a chart of NVDA and TESLA stock price change YTD.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To plot a chart of NVDA (Nvidia Corporation) and TSLA (Tesla Inc.) stock price change Year-to-Date (YTD), you can use the following Python code:\n",
      "```python\n",
      "# filename: stock_chart.py\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from datetime import date, timedelta\n",
      "# Get Yahoo Finance API key\n",
      "API_KEY = '<your-yahoo-finance-api-key>'  # Replace with your own Yahoo Finance API key\n",
      "# Define the stocks to be analyzed\n",
      "stocks = ['NVDA', 'TSLA']\n",
      "# Set the start and end dates for the analysis (YTD)\n",
      "start_date = date.today() - timedelta(days=1)\n",
      "end_date = date.today()\n",
      "# Fetch the stock data from Yahoo Finance API\n",
      "url = f'https://finance.yahoo.com/quote/{stocks[0]}.XML?format=D&range=1d&interval=1mo&lang=en-US&region=US&datatype=chart&caller=YFi_e'\n",
      "data = pd.read_html(url, index_col='Date', thousands=',', decimal='.')[0]\n",
      "for stock in stocks[1:]:\n",
      "    url = f'https://finance.yahoo.com/quote/{stock}.XML?format=D&range=1d&interval=1mo&lang=en-US&region=US&datatype=chart&caller=YFi_e'\n",
      "    data = pd.concat([data, pd.read_html(url, index_col='Date', thousands=',', decimal='.')[0]], axis=1)\n",
      "# Convert the 'Open', 'High', 'Low', and 'Close' columns to float\n",
      "data[['Open', 'High', 'Low', 'Close']] = data[['Open', 'High', 'Low', 'Close']].apply(pd.to_numeric, errors='coerce')\n",
      "# Calculate the percentage change from the first day to the last day\n",
      "data['Percentage Change'] = (data['Close'].iloc[-1] / data['Close'].iloc[0] - 1) * 100\n",
      "# Filter the data for the specified date range\n",
      "data = data[(data.index >= start_date) & (data.index <= end_date)]\n",
      "# Plot the stock chart\n",
      "fig, ax = plt.subplots()\n",
      "data[['NVDA', 'Percentage Change']].plot(ax=ax)\n",
      "data[['TSLA', 'Percentage Change']].plot(ax=ax)\n",
      "ax.set_title('Year-to-Date Stock Price Change')\n",
      "ax.legend(['NVDA', 'TSLA'], loc='upper left')\n",
      "plt.show()\n",
      "```\n",
      "Replace `<your-yahoo-finance-api-key>` with your own Yahoo Finance API key, which you can obtain by signing up at https://developer.yahoo.com/login/. The code fetches the stock data from the Yahoo Finance API and plots a chart of the percentage change in NVDA and TSLA stock prices since the beginning of the year using the Matplotlib library.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "UnicodeDecodeError: 'cp950' codec can't decode byte 0xbd in position 81: illegal multibyte sequence\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 59\u001b[0m\n\u001b[0;32m     50\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m UserProxyAgent(\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_proxy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     52\u001b[0m     code_execution_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     max_consecutive_auto_reply\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Kickstart a conversation between the agents to plot a stock price chart\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43massistant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlot a chart of NVDA and TESLA stock price change YTD.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1007\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1006\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[0;32m   1009\u001b[0m     summary_method,\n\u001b[0;32m   1010\u001b[0m     summary_args,\n\u001b[0;32m   1011\u001b[0m     recipient,\n\u001b[0;32m   1012\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:645\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    643\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 645\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m     )\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:810\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    808\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:645\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    643\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 645\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m     )\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:808\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1949\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 1949\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   1951\u001b[0m         log_event(\n\u001b[0;32m   1952\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1953\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1957\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   1958\u001b[0m         )\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1495\u001b[0m, in \u001b[0;36mConversableAgent.generate_code_execution_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;66;03m# found code blocks, execute code and push \"last_n_messages\" back\u001b[39;00m\n\u001b[1;32m-> 1495\u001b[0m exitcode, logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_code_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_blocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1496\u001b[0m code_execution_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_n_messages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m last_n_messages\n\u001b[0;32m   1497\u001b[0m exitcode2str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution succeeded\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exitcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution failed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2133\u001b[0m, in \u001b[0;36mConversableAgent.execute_code_blocks\u001b[1;34m(self, code_blocks)\u001b[0m\n\u001b[0;32m   2131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2132\u001b[0m         filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2133\u001b[0m     exitcode, logs, image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(\n\u001b[0;32m   2134\u001b[0m         code,\n\u001b[0;32m   2135\u001b[0m         lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2136\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m   2137\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_execution_config,\n\u001b[0;32m   2138\u001b[0m     )\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2140\u001b[0m     \u001b[38;5;66;03m# In case the language is not supported, we return an error message.\u001b[39;00m\n\u001b[0;32m   2141\u001b[0m     exitcode, logs, image \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2142\u001b[0m         \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   2143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown language \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2144\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2145\u001b[0m     )\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2108\u001b[0m, in \u001b[0;36mConversableAgent.run_code\u001b[1;34m(self, code, **kwargs)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_code\u001b[39m(\u001b[38;5;28mself\u001b[39m, code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2095\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the code and return the result.\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m \n\u001b[0;32m   2097\u001b[0m \u001b[38;5;124;03m    Override this function to modify the way to run the code.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2106\u001b[0m \u001b[38;5;124;03m        image (str or None): the docker image used for the code execution.\u001b[39;00m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m execute_code(code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\TOMO.Project\\autogen\\venv\\lib\\site-packages\\autogen\\code_utils.py:450\u001b[0m, in \u001b[0;36mexecute_code\u001b[1;34m(code, timeout, filename, work_dir, use_docker, lang)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m         abs_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pathlib\u001b[38;5;241m.\u001b[39mPath(work_dir)\u001b[38;5;241m.\u001b[39mabsolute()) \u001b[38;5;241m+\u001b[39m PATH_SEPARATOR\n\u001b[1;32m--> 450\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;28mstr\u001b[39m(abs_path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    452\u001b[0m     logs \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstdout\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
    "\n",
    "# Load LLM inference endpoints from an environment variable or a file\n",
    "config_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")\n",
    "\n",
    "config_list_gpt35 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-16k-0613\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"tags\": [\"gpt-4o\"]\n",
    "    },  # comment out to get all\n",
    ")\n",
    "\n",
    "config_list_ollama = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"ollama\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_LM_Studio = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"LM Studio\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Define a function for user to choose a model\n",
    "def choose_model():\n",
    "    print(\"Please choose a model from the following options:\")\n",
    "    print(\"1. gpt-3.5-turbo series\")\n",
    "    print(\"2. ollama\")\n",
    "    print(\"3. LM Studio\")\n",
    "    choice = input(\"Enter the number of your choice: \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        return config_list_gpt35\n",
    "    elif choice == \"2\":\n",
    "        return config_list_ollama\n",
    "    elif choice == \"3\":\n",
    "        return config_list_LM_Studio\n",
    "    else:\n",
    "        print(\"Invalid choice, defaulting to ollama.\")\n",
    "        return config_list_ollama\n",
    "\n",
    "# User chooses the model\n",
    "chosen_config_list = choose_model()\n",
    "\n",
    "assistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": chosen_config_list}, max_consecutive_auto_reply=4)\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\", \n",
    "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False}, \n",
    "    llm_config={\"config_list\": chosen_config_list}, \n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=4\n",
    ")\n",
    "\n",
    "# Kickstart a conversation between the agents to plot a stock price chart\n",
    "user_proxy.initiate_chat(assistant, message=\"Plot a chart of NVDA and TESLA stock price change YTD.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
